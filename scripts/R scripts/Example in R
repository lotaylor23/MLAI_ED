R provides libraries that implement logistic regression models, lasso regression, k-folding and others.  
In the language, you are able to compute the results using the glmnet package and plot results to use in your analysis.  
The steps to perform analysis includes:
  Identifying feature and response variables,
  Defining a model to fit your data,
  Split data into train and test,
  Apply the model to your data,
  Optimize or tune,
  Evaluate model performance,
  Report on results.

One example of a generalized solution is shown by the following sample (lasso with k-folding).  
You can find these and others by general web searching for tutorials in regression in R.

#define response variable
y <- dataset$variable

#define matrix of predictor variables
x <- data.matrix(dataset[, c('feature1', 'feature2', 'feature3', 'feature4')])
library(glmnet)

#perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(x, y, alpha = 1)

#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda

#produce plot of test MSE by lambda value
plot(cv_model)

#find coefficients of best model
best_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
coef(best_model)

#define new observation
new = matrix(c(input1, input2, input3, input4), nrow=1, ncol=4) 

#use lasso regression model to predict response value
predict(best_model, s = best_lambda, newx = new)

#use fitted best model to make predictions
y_predicted <- predict(best_model, s = best_lambda, newx = x)

#find SST and SSE
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)

#find R-Squared
rsq <- 1 - sse/sst
rsq
